# -*- coding: utf-8 -*-
"""Lab-4

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1juTU3kGux0gH2OjAjGrg7TdG5P122E75
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

"""# Load the uploaded CSV file into a pandas DataFrame
df = pd.read_csv('ncr_ride_bookings.csv')
"""

df.head(10)

print(df.info())
print(df.isnull().sum())

print(df['Vehicle Type'].value_counts())
# print("\n", data['Pickup Location'].value_counts())
# print("\n", data['Drop Location'].value_counts())
print("\n", df['Booking Status'].value_counts())
print("\n", df['Incomplete Rides Reason'].value_counts())
print("\n", df['Reason for cancelling by Customer'].value_counts())
print("\n", df['Driver Cancellation Reason'].value_counts())
print("\n", df['Payment Method'].value_counts())

plt.figure(figsize = (13, 5))

# Convert 'Date' to datetime and extract the month
df['Date'] = pd.to_datetime(df['Date'])
df['Month'] = df['Date'].dt.month

months = df.groupby('Month').size()

print(months)

# Now let's plot a line plot
sns.lineplot(x = months.index, y = months.values, marker = 'o' )
plt.xlabel('Months')
plt.ylabel('No. of Bookings')
plt.title('Booking by Month')
plt.xticks(ticks=range(1,13), labels=['January', 'February',
'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December'], rotation = 45)

# to show count in each month
for x, y in zip(months.index, months.values):
    plt.text(x, y+10, str(y), ha='center', va='bottom', fontsize=9, fontweight='bold')
plt.show()

plt.figure(figsize = (10, 5))

# Convert 'Date' to datetime and extract the day name
df['Date'] = pd.to_datetime(df['Date'])
df['Day'] = df['Date'].dt.day_name()

day_count = df.groupby('Day').size().reindex(['Monday', 'Tuesday',
                                               'Wednesday', 'Thursday', 'Friday'
                                               , 'Saturday', 'Sunday'])

# Now let's plot a bar plot
sns.barplot(x = day_count.index, y = day_count.values, palette="viridis")
plt.xlabel('Day')
plt.ylabel('No. of Bookings')
plt.title('Booking by Day')

# to show the count on each day
for x, y in enumerate(day_count.values):
    plt.text(x, y+10, str(y), ha='center', va='bottom', fontsize=9, fontweight='bold')
plt.show()

plt.figure(figsize = (10, 5))
vehicle = df.groupby('Vehicle Type').size().sort_values(ascending = False)

## now plot a bar plot

sns.barplot(x = vehicle.values, y = vehicle.index)
plt.title('Popularity of Vehicles')
plt.xlabel('No. of Booking for vehicle')
plt.ylabel('Vehicle Type')

for i, j in enumerate(vehicle.values):
    plt.text(j+10, i, str(j), fontsize=9, fontweight='bold' )
plt.show()

df.info()

#Define the three columns
cols = ["Reason for cancelling by Customer", "Driver Cancellation Reason", "Incomplete Rides Reason"]
titles = ["Canceling by Customer", "Canceling by Driver", "Incomplete Rides"]
#2 rows x 2 columns
fig, axes = plt.subplots(2, 2, figsize=(12, 9))  # bigger figure
axes = axes.flatten()  # flatten to 1D array for easy indexing

for i, (col, title) in enumerate(zip(cols, titles)):
    counts = df[col].value_counts(dropna=True)
    total = counts.sum()

    #Explode slices
    explode = [0.1 if v/total >= 0.15 else 0.05 for v in counts.values]


    wedges, texts, autotexts = axes[i].pie(
        counts,
        labels=counts.index,
        autopct='%1.1f%%',
        startangle=140,
        shadow=True,
        explode=explode,
        wedgeprops={'edgecolor': 'black'},
        colors= sns.color_palette("deep") ,
    )

    for text in texts:
        text.set_fontsize(10)
        text.set_color('black')
    for autotext in autotexts:
        autotext.set_fontsize(11)
        autotext.set_color('white')
        autotext.set_fontweight('bold')

    axes[i].set_title(title, fontsize=15, fontweight='bold')
    axes[i].set_aspect('equal')

#Remove the empty 4th subplot
fig.delaxes(axes[3])

plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score
import tensorflow as tf
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense

# Select only numerical columns for features (X)
X = df.select_dtypes(include=np.number).values
y = df.iloc[:, -1].values

# Encode target if categorical
if y.dtype == 'object':
    le = LabelEncoder()
    y = le.fit_transform(y)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Normalize features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# --------------------------
# 3. Feed-Forward Neural Network (FFNN)
# --------------------------
ffnn = Sequential([
    Dense(8, input_dim=X_train.shape[1], activation='relu'),
    Dense(1, activation='sigmoid')
])
ffnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

history_f = ffnn.fit(X_train, y_train, epochs=10, verbose=0, validation_data=(X_test, y_test))
acc_f = ffnn.evaluate(X_test, y_test, verbose=0)[1]

# --------------------------
# 5. XOR Problem Demonstration
# --------------------------
X_xor = np.array([[0,0],[0,1],[1,0],[1,1]])
y_xor = np.array([0,1,1,0])

# Perceptron (fails on XOR)
perceptron_xor = Sequential([
    Dense(1, input_dim=2, activation='sigmoid')
])
perceptron_xor.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])
perceptron_xor.fit(X_xor, y_xor, epochs=200, verbose=0)
acc_xor_p = perceptron_xor.evaluate(X_xor, y_xor, verbose=0)[1]

# MLP (solves XOR)
mlp_xor = Sequential([
    Dense(4, input_dim=2, activation='relu'),
    Dense(1, activation='sigmoid')
])
mlp_xor.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
mlp_xor.fit(X_xor, y_xor, epochs=200, verbose=0)
acc_xor_m = mlp_xor.evaluate(X_xor, y_xor, verbose=0)[1]

# --------------------------
# 6. Accuracy Comparison Table
# --------------------------
import pandas as pd

results = pd.DataFrame({
    "Model": ["Perceptron", "FFNN", "MLP", "Perceptron-XOR", "MLP-XOR"],
    "Accuracy": [acc_p, acc_f, acc_m, acc_xor_p, acc_xor_m]
})
print("\nAccuracy Comparison:")
print(results)

# --------------------------
# 7. Plot training loss
# --------------------------
plt.figure(figsize=(10,5))
plt.plot(history_p.history['loss'], label="Perceptron Loss")
plt.plot(history_f.history['loss'], label="FFNN Loss")
plt.plot(history_m.history['loss'], label="MLP Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.title("Training Loss Comparison")
plt.legend()
plt.show()

# --------------------------
# 4. Multi-Layer Perceptron (MLP)
# --------------------------
mlp = Sequential([
    Dense(16, input_dim=X_train.shape[1], activation='relu'),
    Dense(8, activation='relu'),
    Dense(1, activation='sigmoid')
])
mlp.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

history_m = mlp.fit(X_train, y_train, epochs=10, verbose=0, validation_data=(X_test, y_test))
acc_m = mlp.evaluate(X_test, y_test, verbose=0)[1]

# --------------------------
# 5. XOR Problem Demonstration
# --------------------------
import matplotlib.pyplot as plt
import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

X_xor = np.array([[0,0],[0,1],[1,0],[1,1]])
y_xor = np.array([0,1,1,0])

# Perceptron (fails on XOR)
perceptron_xor = Sequential([
    Dense(1, input_dim=2, activation='sigmoid')
])
perceptron_xor.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])
history_xor_p = perceptron_xor.fit(X_xor, y_xor, epochs=200, verbose=0)
acc_xor_p = perceptron_xor.evaluate(X_xor, y_xor, verbose=0)[1]

# MLP (solves XOR)
mlp_xor = Sequential([
    Dense(4, input_dim=2, activation='relu'),
    Dense(1, activation='sigmoid')
])
mlp_xor.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
history_xor_m = mlp_xor.fit(X_xor, y_xor, epochs=200, verbose=0)
acc_xor_m = mlp_xor.evaluate(X_xor, y_xor, verbose=0)[1]

# --------------------------
# 6. Accuracy Comparison Table
# --------------------------
import pandas as pd

# You need to define these variables first (from previous models)
# For demonstration, I'll create placeholder values
acc_p, acc_f, acc_m = 0.1425, 0.1425, 0.1425  # Replace with your actual values

results = pd.DataFrame({
    "Model": ["Perceptron", "FFNN", "MLP", "Perceptron-XOR", "MLP-XOR"],
    "Accuracy": [acc_p, acc_f, acc_m, acc_xor_p, acc_xor_m]
})
print("\nAccuracy Comparison:")
print(results)

# --------------------------
# 7. Plot training loss for XOR models
# --------------------------
plt.figure(figsize=(10,5))
plt.plot(history_xor_p.history['loss'], label="Perceptron-XOR Loss")
plt.plot(history_xor_m.history['loss'], label="MLP-XOR Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.title("XOR Problem Training Loss Comparison")
plt.legend()
plt.show()

# --------------------------
# 8. Create a bar chart for accuracy comparison
# --------------------------
plt.figure(figsize=(10, 6))
plt.bar(results["Model"], results["Accuracy"])
plt.xlabel("Model")
plt.ylabel("Accuracy")
plt.title("Model Accuracy Comparison")
plt.ylim(0, 1)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# --------------------------
# 9. Create a visualization of XOR decision boundaries
# --------------------------
def plot_decision_boundary(model, X, y):
    # Create a mesh grid
    x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1
    y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1
    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),
                         np.linspace(y_min, y_max, 100))

    # Predict for each point in the grid
    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)

    # Plot contour and training examples
    plt.contourf(xx, yy, Z, alpha=0.3)
    plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.Spectral)
    plt.title(f"Decision Boundary (Accuracy: {model.evaluate(X, y, verbose=0)[1]:.2f})")
    plt.xlabel("Feature 1")
    plt.ylabel("Feature 2")

# Plot for both models
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plot_decision_boundary(perceptron_xor, X_xor, y_xor)
plt.title("Perceptron (Cannot solve XOR)")

plt.subplot(1, 2, 2)
plot_decision_boundary(mlp_xor, X_xor, y_xor)
plt.title("MLP (Solves XOR)")

plt.tight_layout()
plt.show()